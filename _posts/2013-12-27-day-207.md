---
layout: post
title: Day 207&#58 How to count things.
permalink: day-207.html
comments: true
---

## Hacker School: day 207.

*(My batch ended on August 22, 2013, but as they say, [never graduate](https://www.hackerschool.com/).)*

I've been playing with [Brushfire](https://github.com/avibryant/brushfire), which is a machine learning library that distributes the learning of [decision trees](http://en.wikipedia.org/wiki/Decision_tree) across a cluster.

Most of ML is basically aggregating counts of stuff, and Brushfire is no different. What's sort of interesting is the way Brushfire does this &mdash; it uses a fascinating little library called [Algebird](https://github.com/twitter/algebird).

The idea behind Algebird is this.

* Sometimes you need to count so many things that one machine can't process the counts quickly enough.
* The problem of distributing an aggregation problem across a cluster of computers can be made a lot easier if you know about the *algebraic structure* of the aggregation problem.
* Which means that if you phrase problems using Algebird's data structures, it is almost trivial to turn them into MapReduce jobs or Storm topologies (or something else).

When I say **algebraic structure** here, I mean something slightly different than what you learned about in grade school. I'm talking about general, abstract mathematical properties of the aggregation problem. For example, consider that in normal addition, it doesn't matter in which order you add some numbers. If I want to aggregate this sum:

`\[ 1 + 2 + 3 + 4 + 5 + 6 \]`

I can decide to add them up in basically whatever order I want. Like starting from the left:

`\[ ((((1 + 2) + 3) + 4) + 5) + 6 \]`

Or from the right:

`\[ 1 + (2 + (3 + (4 + (5 + 6)))) \]`

Or in a different order entirely:

`\[ 6 + 4 + 1 + 2 + 3 + 5 \]`

This means that if you make a cluster of computers add up these numbers, **it doesn't matter which computer adds up which numbers, as long as they all get added eventually**.

Something similar also holds for finding the largest number in a stream &mdash; it doesn't matter which computer processes which numbers, as long as they all report the largest number they've seen, and as long as you process all the numbers, you can continually aggregate until you have one number, which is always your largest number.

In the terminology of algebra, the natural numbers are a *monoid* under addition and the "largest number" operation.

Monoids are just one type of algebraic data structure that Algebird provides interfaces for. There are [many more](https://github.com/twitter/algebird/wiki/Abstract-algebra-definitions). Each of these has different guarantees for how they can be distributed across a cluster, meaning that if you can phrase your aggregation problem in terms of these, it is much easier to distribute your problem across a cluster.

[Here](http://www.michael-noll.com/blog/2013/12/02/twitter-algebird-monoid-monad-for-large-scala-data-analytics/) is a good summary of what other sorts of problems can be approached using these strucutres, but a general guideline seems to be that they are particularly good for problems that look kind of like counting. Frequency estimation, top n frequent items, SGD, *etc*.